[aws]
# The S3 bucket name to copy the SQL to. This should be empty, as the script will create folders named $schema_name/$table_name-[...] under this bucket
s3_bucket=your-s3-bucket-name
# AWS Credentials to use. S3 write access required.
access_key=s3-access-key-here
secret_key=s3-secret-key-here

[redshift]
# Source host / user / password
source_host=redshift.yoursite.com
source_user=admin
source_password=imasupersecretpassword

# Destination host / user / password
dest_host=newredshift.yoursite.com
dest_user=admin
dest_password=evenmoresecretpassword

# The database name to use. This must be the same on both servers.
dbname=dbname
# The schema to use. All tables under this schema will be exported to S3.
## This script assumes you have less than a hundred or so tables in this schema.
## If you have a large amount of tables in this schema, the script might complain about spawning too many processes,
## or redshift might complain. Untested?
schema=schema-to-copy
